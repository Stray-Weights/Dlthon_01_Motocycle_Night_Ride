{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Stray-Weights/Dlthon_01_Motocycle_Night_Ride/blob/main/final_work/3_%EA%B8%B0%EB%8A%A5%EA%B5%AC%ED%98%84.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_4b47FGfnpH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "===============================================================================\n",
        "ì´ íŒŒì¼ì€ ì•¼ê°„ ì£¼í–‰ ì•ˆì „ ì§€ìˆ˜ ì‹œìŠ¤í…œì˜ ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ êµ¬í˜„í•©ë‹ˆë‹¤:\n",
        "  1. ë°•í•­ì•„: ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡\n",
        "  2. ë°•ë¬´ë¦¼: ì˜ˆì¸¡ ê²°ê³¼ ë¶„ì„ ë° ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„±\n",
        "===============================================================================\n",
        "\"\"\"\n",
        "\n",
        "# ============================================================================\n",
        "# [ë°•í•­ì•„ íŒŒì¼] Step 0 - ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
        "# ============================================================================"
      ],
      "metadata": {
        "id": "6YMSZlNUfope"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms as T\n",
        "from torchvision.transforms import InterpolationMode\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# ì¶”ê°€ ì„í¬íŠ¸ (ë°•ë¬´ë¦¼ íŒŒì¼ìš©)\n",
        "from tqdm.auto import tqdm\n",
        "import pandas as pd\n",
        "from dataclasses import dataclass\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Device ì„¤ì •\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ì¥ì¹˜: {device}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqELHR_7gHh-",
        "outputId": "186248ce-6c7b-47f5-d55e-da06267a46bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ì¥ì¹˜: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ============================================================================\n",
        "# [ë°•í•­ì•„ íŒŒì¼] PathManager í´ë˜ìŠ¤ ì„ ì–¸\n",
        "# ============================================================================"
      ],
      "metadata": {
        "id": "PsD9BzrpgLvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PathManager:\n",
        "    \"\"\"í™˜ê²½ ë° ëª¨ë“ˆ ê°„ ê·œê²© í´ë˜ìŠ¤\"\"\"\n",
        "    \"\"\"ìƒí™©ì— ë§ê²Œ ê²½ë¡œì™€ ê·œê²©ì„ ìˆ˜ì • í›„ ì‚¬ìš©í•  ê²ƒ\"\"\"\n",
        "\n",
        "    def __init__(self, project_path: str | Path | None = None, data_sub_path: str = \"data\", default_size: int | None = None):\n",
        "        # 1. ë£¨íŠ¸ ê²½ë¡œ ê²°ì • (ì œê³µëœ ê²½ë¡œê°€ ì—†ìœ¼ë©´ ìë™ íƒìƒ‰)\n",
        "        if project_path:\n",
        "            self.root_path = Path(project_path)\n",
        "            print(f\"ğŸ“ ì„¤ì •ëœ í”„ë¡œì íŠ¸ ê²½ë¡œ ì‚¬ìš©: {self.root_path}\")\n",
        "        else:\n",
        "            self.root_path = self._find_root()\n",
        "            print(f\"ğŸ” ìë™ íƒìƒ‰ëœ í”„ë¡œì íŠ¸ ê²½ë¡œ: {self.root_path}\")\n",
        "\n",
        "        # 2. .env ë¡œë“œ\n",
        "        self.dotenv_path = self.root_path / \".env\"\n",
        "        if self.dotenv_path.exists():\n",
        "            load_dotenv(self.dotenv_path)\n",
        "            print(\"âœ… .env í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ì™„ë£Œ\")\n",
        "        else:\n",
        "            print(\"âš ï¸  .env íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì„¤ì •ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
        "\n",
        "        load_dotenv(self.dotenv_path)\n",
        "\n",
        "        # 3. ë””ë ‰í† ë¦¬ ê²½ë¡œ ì„¤ì •\n",
        "        self._datas_dir = self.root_path / data_sub_path\n",
        "        self._images_dir = self._datas_dir / 'images'\n",
        "        self._models_dir = self.root_path / 'models'\n",
        "\n",
        "        # 4. ìë™ í´ë” ìƒì„± ë¡œì§\n",
        "        self._make_dirs()\n",
        "\n",
        "        self.default_size = default_size\n",
        "        self.image_name = None\n",
        "        self.model_name = None\n",
        "\n",
        "    def _find_root(self, marker: str = \".env\") -> Path:\n",
        "        \"\"\"í”„ë¡œì íŠ¸ ìµœìƒë‹¨ ê²½ë¡œë¥¼ ì°¾ëŠ” í•¨ìˆ˜\"\"\"\n",
        "        current_cwd = Path().cwd().resolve()\n",
        "\n",
        "        if (current_cwd / marker).exists():\n",
        "            return current_cwd\n",
        "\n",
        "        for parent in current_cwd.parents:\n",
        "            if (parent / marker).exists():\n",
        "                return parent\n",
        "\n",
        "        return current_cwd  # ê¸°ë³¸ê°’\n",
        "\n",
        "    def _make_dirs(self):\n",
        "        \"\"\"í•„ìš”í•œ ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±í•©ë‹ˆë‹¤.\"\"\"\n",
        "        target_dirs = [self._images_dir, self._models_dir, self._datas_dir]\n",
        "        for path in target_dirs:\n",
        "            path.mkdir(parents=True, exist_ok=True)\n",
        "            print(f\"ì¤€ë¹„ ì™„ë£Œ: {path}\")\n",
        "\n",
        "    # --- ê²½ë¡œ íšë“ ë©”ì„œë“œ ---\n",
        "    def get_image_path(self, image_name: str) -> Path:\n",
        "        \"\"\"ì´ë¯¸ì§€ ì£¼ì†Œ íšë“\"\"\"\n",
        "        self.image_name = image_name\n",
        "        return self._images_dir / image_name\n",
        "\n",
        "    def get_model_path(self, model_name: str) -> Path:\n",
        "        \"\"\"ëª¨ë¸ ì£¼ì†Œ íšë“\"\"\"\n",
        "        self.model_name = model_name\n",
        "        return self._models_dir / model_name\n",
        "\n",
        "    def get_data_path(self, data_name: str) -> Path:\n",
        "        \"\"\"ë°ì´í„° ì£¼ì†Œ íšë“\"\"\"\n",
        "        self.data_name = data_name\n",
        "        return self._datas_dir / data_name"
      ],
      "metadata": {
        "id": "h0blP9gIgPwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ============================================================================\n",
        "# [ë°•ë¬´ë¦¼ íŒŒì¼] Section 1: ê²½ë¡œ ê´€ë¦¬ í´ë˜ìŠ¤ (PathManager í†µí•©)\n",
        "# ============================================================================"
      ],
      "metadata": {
        "id": "AEB7fHnvgUv2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResultPathManager:\n",
        "    \"\"\"ë¶„ì„ ê²°ê³¼ ì €ì¥ ê²½ë¡œë¥¼ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤\"\"\"\n",
        "\n",
        "    def __init__(self, base_path=None):\n",
        "        if base_path is None:\n",
        "            if os.path.exists('/content/drive'):\n",
        "                base_path = '/content/drive/MyDrive/murim_results'\n",
        "            else:\n",
        "                base_path = './results'\n",
        "\n",
        "        self.base_path = Path(base_path)\n",
        "        self.base_path.mkdir(parents=True, exist_ok=True)\n",
        "        print(f\"âœ… ResultPathManager ì´ˆê¸°í™”: {self.base_path}\")\n",
        "\n",
        "    def get_data_path(self, filename):\n",
        "        \"\"\"ë°ì´í„° ì €ì¥ ê²½ë¡œ ë°˜í™˜\"\"\"\n",
        "        path = self.base_path / filename\n",
        "        path.parent.mkdir(parents=True, exist_ok=True)\n",
        "        return str(path)\n",
        "\n",
        "    def get_json_path(self):\n",
        "        \"\"\"Result.json ê²½ë¡œ\"\"\"\n",
        "        return self.get_data_path(\"Result.json\")\n",
        "\n",
        "    def get_analysis_path(self):\n",
        "        \"\"\"ë¶„ì„ ê²°ê³¼ CSV ê²½ë¡œ\"\"\"\n",
        "        return self.get_data_path(\"analysis_results.csv\")\n"
      ],
      "metadata": {
        "id": "4jkwH7DJgZWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ============================================================================\n",
        "# [ë°•ë¬´ë¦¼ íŒŒì¼] Section 2: ì˜ˆì¸¡ ê²°ê³¼ë¥¼ COCO JSONìœ¼ë¡œ ì €ì¥\n",
        "# ============================================================================"
      ],
      "metadata": {
        "id": "CKHeq8lJgfeh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_predictions_to_coco(model, test_loader, device, class_map, path_manager):\n",
        "    \"\"\"\n",
        "    ========================================================================\n",
        "    ì˜ˆì¸¡ ê²°ê³¼ë¥¼ COCO í˜•ì‹ì˜ JSONìœ¼ë¡œ ë³€í™˜ ë° ì €ì¥\n",
        "    ========================================================================\n",
        "\n",
        "    ì—­í• :\n",
        "        - ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ì˜ ì¶œë ¥ì„ COCO í˜•ì‹ì˜ JSONìœ¼ë¡œ ë³€í™˜\n",
        "        - ê° ê°ì²´ì˜ í´ë¦¬ê³¤, ë°”ìš´ë”©ë°•ìŠ¤, ë©´ì  ì •ë³´ í¬í•¨\n",
        "\n",
        "    ì…ë ¥:\n",
        "        model: PyTorch ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ (output['out'] shape: [B, C, H, W])\n",
        "        test_loader: DataLoader (ì´ë¯¸ì§€, _ íŠœí”Œ ë°˜í™˜)\n",
        "        device: 'cuda' ë˜ëŠ” 'cpu'\n",
        "        class_map: í´ë˜ìŠ¤ ë§¤í•‘ {\"Undrivable\": 0, \"Drivable\": 1, ...}\n",
        "        path_manager: PathManager ë˜ëŠ” ResultPathManager ì¸ìŠ¤í„´ìŠ¤\n",
        "\n",
        "    ì¶œë ¥:\n",
        "        - Result.json íŒŒì¼ ìƒì„±\n",
        "        - ë”•ì…”ë„ˆë¦¬ ë°˜í™˜ (images, annotations, categories)\n",
        "    ========================================================================\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # 1. COCO JSON ê¸°ë³¸ êµ¬ì¡°\n",
        "    results = {\n",
        "        \"images\": [],\n",
        "        \"annotations\": [],\n",
        "        \"categories\": [{\"id\": v, \"name\": k} for k, v in class_map.items()]\n",
        "    }\n",
        "\n",
        "    ann_id = 1\n",
        "    image_id_count = 1\n",
        "\n",
        "    print(\"\\nâ³ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ COCO JSONìœ¼ë¡œ ë³€í™˜ ì¤‘...\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, _ in tqdm(test_loader, desc=\"Processing images\"):\n",
        "            images = images.to(device)\n",
        "\n",
        "            # ëª¨ë¸ ì˜ˆì¸¡\n",
        "            outputs = model(images)['out']\n",
        "\n",
        "            # ê° í”½ì…€ì—ì„œ í™•ë¥ ì´ ê°€ì¥ ë†’ì€ í´ë˜ìŠ¤ ì„ íƒ\n",
        "            preds = torch.argmax(outputs, dim=1).cpu().numpy()  # [Batch, H, W]\n",
        "\n",
        "            for batch_idx in range(len(preds)):\n",
        "                file_name = f\"result_{image_id_count:06d}.png\"\n",
        "\n",
        "                # 2. ì´ë¯¸ì§€ ì •ë³´ ì¶”ê°€\n",
        "                results[\"images\"].append({\n",
        "                    \"id\": image_id_count,\n",
        "                    \"file_name\": file_name,\n",
        "                    \"width\": 528,\n",
        "                    \"height\": 528\n",
        "                })\n",
        "\n",
        "                # 3. ê° í´ë˜ìŠ¤ë³„ë¡œ ì–´ë…¸í…Œì´ì…˜ ìƒì„±\n",
        "                pred_mask = preds[batch_idx]  # [528, 528]\n",
        "\n",
        "                for class_name, class_idx in class_map.items():\n",
        "                    if class_idx == 0:\n",
        "                        continue  # ë°°ê²½(Undrivable) ì œì™¸\n",
        "\n",
        "                    # í•´ë‹¹ í´ë˜ìŠ¤ì˜ ì´ì§„ ë§ˆìŠ¤í¬ ìƒì„±\n",
        "                    class_mask = (pred_mask == class_idx).astype(np.uint8)\n",
        "\n",
        "                    # ì™¸ê³½ì„ (Contour) ì°¾ê¸°\n",
        "                    contours, _ = cv2.findContours(\n",
        "                        class_mask,\n",
        "                        cv2.RETR_EXTERNAL,\n",
        "                        cv2.CHAIN_APPROX_SIMPLE\n",
        "                    )\n",
        "\n",
        "                    for contour in contours:\n",
        "                        # ìµœì†Œ 3ê°œì˜ ì  í•„ìš”\n",
        "                        if len(contour) < 3:\n",
        "                            continue\n",
        "\n",
        "                        # COCO í´ë¦¬ê³¤ í˜•ì‹: [x1, y1, x2, y2, ...]\n",
        "                        segmentation = contour.flatten().tolist()\n",
        "\n",
        "                        # ë°”ìš´ë”©ë°•ìŠ¤: [x, y, width, height]\n",
        "                        x, y, w, h = cv2.boundingRect(contour)\n",
        "                        area = float(cv2.contourArea(contour))\n",
        "\n",
        "                        # ë„ˆë¬´ ì‘ì€ ë…¸ì´ì¦ˆ ì œê±°\n",
        "                        if area < 10:\n",
        "                            continue\n",
        "\n",
        "                        # ì–´ë…¸í…Œì´ì…˜ ì¶”ê°€\n",
        "                        results[\"annotations\"].append({\n",
        "                            \"id\": ann_id,\n",
        "                            \"image_id\": image_id_count,\n",
        "                            \"category_id\": class_idx,\n",
        "                            \"segmentation\": [segmentation],\n",
        "                            \"area\": area,\n",
        "                            \"bbox\": [x, y, w, h],\n",
        "                            \"iscrowd\": 0\n",
        "                        })\n",
        "                        ann_id += 1\n",
        "\n",
        "                image_id_count += 1\n",
        "\n",
        "    # 4. JSON íŒŒì¼ ì €ì¥\n",
        "    save_path = path_manager.get_json_path()\n",
        "    with open(save_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(results, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "    # 5. ê²°ê³¼ ì¶œë ¥\n",
        "    print(f\"\\nâœ… COCO JSON ì €ì¥ ì™„ë£Œ\")\n",
        "    print(f\"   ê²½ë¡œ: {save_path}\")\n",
        "    print(f\"   ğŸ“Š í†µê³„:\")\n",
        "    print(f\"      - ì´ë¯¸ì§€ ìˆ˜: {len(results['images'])}\")\n",
        "    print(f\"      - ì–´ë…¸í…Œì´ì…˜ ìˆ˜: {len(results['annotations'])}\")\n",
        "    print(f\"      - ì¹´í…Œê³ ë¦¬ ìˆ˜: {len(results['categories'])}\")\n",
        "\n",
        "    return results\n",
        "\n"
      ],
      "metadata": {
        "id": "QWoeo5EhgoHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ============================================================================\n",
        "# [ë°•ë¬´ë¦¼ íŒŒì¼] Section 3: ìµœì¢… í†µí•© ë¶„ì„ í´ë˜ìŠ¤\n",
        "# ============================================================================"
      ],
      "metadata": {
        "id": "7mb41voigqnD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MurimFinalIntegration:\n",
        "    \"\"\"ë°•ë¬´ë¦¼ì´ ê°œë°œí•œ ì§€ëŠ¥í˜• ììœ¨ì£¼í–‰ ë¶„ì„ ì—”ì§„\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.prev_distance = None  # ì‹œê³„ì—´ ë¶„ì„ìš© ë©”ëª¨ë¦¬\n",
        "        # ë¬¼ë¦¬ íŒŒë¼ë¯¸í„°\n",
        "        self.camera_h = 1.2\n",
        "        self.focal_l = 1200\n",
        "\n",
        "    def process_step_34_logic(self, annotations, img_info):\n",
        "        \"\"\"\n",
        "        [ê¸°ì¡´ ì„¹ì…˜ 3, 4ì˜ ê¸°ëŠ¥ì„ ëª¨ë‘ í¬í•¨]\n",
        "        íŒ€ì¥ë‹˜ì˜ JSON ë°ì´í„°ë¥¼ ë°›ì•„ ê±°ë¦¬ ê³„ì‚° ë° ìœ„í—˜ íŒë‹¨ ìˆ˜í–‰\n",
        "        \"\"\"\n",
        "        img_h = img_info['height']\n",
        "\n",
        "        # [Task 2] ê³ ìœ  ID ì‹ë³„\n",
        "        ID_RIDER = 1329681      # Rider\n",
        "        ID_MOVEABLE = 1323884   # Moveable (ì°¨ëŸ‰)\n",
        "        ID_ROAD = 1323881       # Road\n",
        "\n",
        "        # ê°ì²´ í•„í„°ë§\n",
        "        rider_anns = [a for a in annotations if a['category_id'] == ID_RIDER]\n",
        "        moveable_anns = [a for a in annotations if a['category_id'] == ID_MOVEABLE]\n",
        "\n",
        "        # [Task 5] ë„ë¡œ í˜¼ì¡ë„ (ì°¨ëŸ‰ ëŒ€ìˆ˜ í™•ì¸)\n",
        "        moveable_count = len(moveable_anns)\n",
        "        congestion = \"í˜¼ì¡\" if moveable_count >= 3 else \"ì›í™œ\"\n",
        "\n",
        "        # ê²°ê³¼ ì €ì¥ ê¸°ë³¸ êµ¬ì¡°\n",
        "        report = {\"pixel_dist\": 0, \"real_dist\": 0, \"congestion\": congestion, \"status\": \"SAFE\", \"count\": moveable_count}\n",
        "\n",
        "        if rider_anns and moveable_anns:\n",
        "            # 1. [Task 3] í”½ì…€ ê±°ë¦¬ ê³„ì‚° (Rider vs Moveable)\n",
        "            rx, ry, rw, rh = rider_anns[0]['bbox']\n",
        "            mx, my, mw, mh = moveable_anns[0]['bbox']\n",
        "\n",
        "            # í•˜ë‹¨ ì¤‘ì•™ì  ê¸°ì¤€ í”½ì…€ ê°„ê²© ê³„ì‚°\n",
        "            pix_dist = np.sqrt(((rx+rw/2)-(mx+mw/2))**2 + ((ry+rh)-(my+mh))**2)\n",
        "            report[\"pixel_dist\"] = round(pix_dist, 2)\n",
        "\n",
        "            # 2. [Task 4] ì‹¤ì œ ë¯¸í„°(m) ë³€í™˜ (ê¸°ì¡´ ì„¹ì…˜ 3ì˜ í•µì‹¬ ë¬¼ë¦¬ ê³µì‹)\n",
        "            v_horizon = img_h * 0.5\n",
        "            # d = (H * f) / (y - v_horizon) -> í•µì‹¬ ê±°ë¦¬ ê³µì‹\n",
        "            real_dist = (self.camera_h * self.focal_l) / (my + mh - v_horizon) if (my + mh - v_horizon) > 0 else 50.0\n",
        "            report[\"real_dist\"] = round(real_dist, 2)\n",
        "\n",
        "            # 3. [Task 6] ì‹œê³„ì—´ ì¶©ëŒ ê²½ê³ \n",
        "            if self.prev_distance is not None:\n",
        "                distance_change = self.prev_distance - real_dist\n",
        "                if distance_change > 0.5:  # 0.5m ì´ìƒ ì ‘ê·¼\n",
        "                    report[\"status\"] = \"âš ï¸  WARNING\"\n",
        "                if distance_change > 2.0:  # 2m ì´ìƒ ê¸‰ì ‘ê·¼\n",
        "                    report[\"status\"] = \"ğŸš¨ CRITICAL\"\n",
        "\n",
        "            self.prev_distance = real_dist\n",
        "\n",
        "        return report\n"
      ],
      "metadata": {
        "id": "W0D4o4JhguUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ============================================================================\n",
        "# [ë°•ë¬´ë¦¼ íŒŒì¼] Section 4: ê²°ê³¼ ë¶„ì„ í•¨ìˆ˜\n",
        "# ============================================================================"
      ],
      "metadata": {
        "id": "RIQ2x3Jmg3g9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_team_result_json(result_json=None, result_json_path=None, path_manager=None):\n",
        "    \"\"\"\n",
        "    ========================================================================\n",
        "    íŒ€ì¥ì˜ Result.jsonì„ ë¶„ì„í•˜ì—¬ ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„±\n",
        "    ========================================================================\n",
        "\n",
        "    ì…ë ¥:\n",
        "        result_json: COCO JSON ë”•ì…”ë„ˆë¦¬ (ë˜ëŠ” None)\n",
        "        result_json_path: JSON íŒŒì¼ ê²½ë¡œ (ë¬¸ìì—´)\n",
        "        path_manager: PathManager ë˜ëŠ” ResultPathManager ì¸ìŠ¤í„´ìŠ¤\n",
        "\n",
        "    ì¶œë ¥:\n",
        "        ë¶„ì„ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜\n",
        "    ========================================================================\n",
        "    \"\"\"\n",
        "\n",
        "    # JSON ë°ì´í„° ë¡œë“œ\n",
        "    if result_json_path:\n",
        "        with open(result_json_path, 'r', encoding='utf-8') as f:\n",
        "            results = json.load(f)\n",
        "    else:\n",
        "        results = result_json\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"ğŸ” ë¶„ì„: íŒ€ì¥ì˜ Result.json ì²˜ë¦¬ ì¤‘...\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # ë¶„ì„ ê²°ê³¼ ì €ì¥ì†Œ\n",
        "    analysis_results = []\n",
        "\n",
        "    # ì´ë¯¸ì§€ë³„ ë¶„ì„\n",
        "    for image_info in results.get('images', []):\n",
        "        img_id = image_info['id']\n",
        "        img_h = image_info['height']\n",
        "        img_w = image_info['width']\n",
        "\n",
        "        # í•´ë‹¹ ì´ë¯¸ì§€ì˜ ì–´ë…¸í…Œì´ì…˜ í•„í„°ë§\n",
        "        image_annotations = [\n",
        "            a for a in results['annotations']\n",
        "            if a['image_id'] == img_id\n",
        "        ]\n",
        "\n",
        "        # í´ë˜ìŠ¤ë³„ í†µê³„\n",
        "        class_stats = {}\n",
        "        total_area = 0\n",
        "\n",
        "        for ann in image_annotations:\n",
        "            cat_id = ann['category_id']\n",
        "            area = ann.get('area', 0)\n",
        "            bbox = ann.get('bbox', [0, 0, 0, 0])\n",
        "\n",
        "            if cat_id not in class_stats:\n",
        "                class_stats[cat_id] = {\n",
        "                    'count': 0,\n",
        "                    'total_area': 0,\n",
        "                    'avg_bbox': [0, 0, 0, 0],\n",
        "                    'items': []\n",
        "                }\n",
        "\n",
        "            class_stats[cat_id]['count'] += 1\n",
        "            class_stats[cat_id]['total_area'] += area\n",
        "            class_stats[cat_id]['items'].append({\n",
        "                'bbox': bbox,\n",
        "                'area': area\n",
        "            })\n",
        "            total_area += area\n",
        "\n",
        "        # í‰ê·  ë°”ìš´ë”©ë°•ìŠ¤ ê³„ì‚°\n",
        "        for cat_id in class_stats:\n",
        "            items = class_stats[cat_id]['items']\n",
        "            if items:\n",
        "                avg_x = np.mean([item['bbox'][0] for item in items])\n",
        "                avg_y = np.mean([item['bbox'][1] for item in items])\n",
        "                avg_w = np.mean([item['bbox'][2] for item in items])\n",
        "                avg_h = np.mean([item['bbox'][3] for item in items])\n",
        "                class_stats[cat_id]['avg_bbox'] = [avg_x, avg_y, avg_w, avg_h]\n",
        "\n",
        "        # ê°„ë‹¨í•œ ë„ë¡œ í˜¼ì¡ë„ ê³„ì‚° (ì–´ë…¸í…Œì´ì…˜ ìˆ˜ ê¸°ë°˜)\n",
        "        if len(image_annotations) > 10:\n",
        "            congestion = \"í˜¼ì¡\"\n",
        "        elif len(image_annotations) > 5:\n",
        "            congestion = \"ë³´í†µ\"\n",
        "        else:\n",
        "            congestion = \"ì›í™œ\"\n",
        "\n",
        "        # ì•ˆì „ íŒì • (ë©´ì  ê¸°ë°˜ ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)\n",
        "        safety_status = \"SAFE\"\n",
        "        if total_area > (img_h * img_w * 0.5):  # 50% ì´ìƒ ì ìœ \n",
        "            safety_status = \"âš ï¸  WARNING\"\n",
        "        if total_area > (img_h * img_w * 0.7):  # 70% ì´ìƒ ì ìœ \n",
        "            safety_status = \"ğŸš¨ CRITICAL\"\n",
        "\n",
        "        # ê²°ê³¼ ì €ì¥\n",
        "        result = {\n",
        "            'image_id': img_id,\n",
        "            'file_name': image_info['file_name'],\n",
        "            'image_size': (img_w, img_h),\n",
        "            'annotation_count': len(image_annotations),\n",
        "            'total_area': total_area,\n",
        "            'congestion': congestion,\n",
        "            'safety_status': safety_status,\n",
        "            'class_stats': class_stats\n",
        "        }\n",
        "\n",
        "        analysis_results.append(result)\n",
        "\n",
        "    # ì¢…í•© ë¦¬í¬íŠ¸\n",
        "    print(\"\\nğŸ“Š ë¶„ì„ ê²°ê³¼ ìš”ì•½\")\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "    if len(analysis_results) > 0:\n",
        "        # ì²˜ìŒ 5ê°œ ì´ë¯¸ì§€ë§Œ ìƒì„¸ ì¶œë ¥\n",
        "        for idx, result in enumerate(analysis_results[:5], 1):\n",
        "            print(f\"\\n[{idx}] {result['file_name']}\")\n",
        "            print(f\"    â”Œâ”€ ì´ë¯¸ì§€ í¬ê¸°: {result['image_size']}\")\n",
        "            print(f\"    â”œâ”€ ì–´ë…¸í…Œì´ì…˜: {result['annotation_count']}ê°œ\")\n",
        "            print(f\"    â”œâ”€ ì ìœ  ë©´ì : {result['total_area']:.0f}pxÂ² \"\n",
        "                  f\"({100*result['total_area']/(result['image_size'][0]*result['image_size'][1]):.1f}%)\")\n",
        "            print(f\"    â”œâ”€ í˜¼ì¡ë„: {result['congestion']}\")\n",
        "            print(f\"    â””â”€ ìƒíƒœ: {result['safety_status']}\")\n",
        "\n",
        "            for cat_id, stats in result['class_stats'].items():\n",
        "                cat_name = [c['name'] for c in results['categories'] if c['id'] == cat_id]\n",
        "                cat_name = cat_name[0] if cat_name else f\"Cat#{cat_id}\"\n",
        "                print(f\"       â€¢ {cat_name}: {stats['count']}ê°œ, \"\n",
        "                      f\"ë©´ì ={stats['total_area']:.0f}, \"\n",
        "                      f\"bbox={[round(x, 1) for x in stats['avg_bbox']]}\")\n",
        "\n",
        "        if len(analysis_results) > 5:\n",
        "            print(f\"\\n   ... ì´ì™¸ {len(analysis_results) - 5}ê°œ ì´ë¯¸ì§€\")\n",
        "\n",
        "    # ì „ì²´ í†µê³„\n",
        "    total_annotations = sum(r['annotation_count'] for r in analysis_results)\n",
        "    avg_congestion = np.mean([\n",
        "        {'í˜¼ì¡': 3, 'ë³´í†µ': 2, 'ì›í™œ': 1}.get(r['congestion'], 1)\n",
        "        for r in analysis_results\n",
        "    ]) if analysis_results else 0\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"ğŸ“ˆ ì „ì²´ í†µê³„\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"  â€¢ ì²˜ë¦¬ëœ ì´ë¯¸ì§€: {len(analysis_results)}ê°œ\")\n",
        "    print(f\"  â€¢ ì´ ì–´ë…¸í…Œì´ì…˜: {total_annotations}ê°œ\")\n",
        "    print(f\"  â€¢ í‰ê·  í˜¼ì¡ë„: {avg_congestion:.2f}/3 \"\n",
        "          f\"({'í˜¼ì¡' if avg_congestion > 2 else 'ë³´í†µ' if avg_congestion > 1 else 'ì›í™œ'})\")\n",
        "\n",
        "    # CSVë¡œ ì €ì¥\n",
        "    if path_manager:\n",
        "        csv_path = path_manager.get_analysis_path()\n",
        "\n",
        "        # DataFrame êµ¬ì„±\n",
        "        df_data = []\n",
        "        for result in analysis_results:\n",
        "            df_data.append({\n",
        "                'image_id': result['image_id'],\n",
        "                'file_name': result['file_name'],\n",
        "                'annotation_count': result['annotation_count'],\n",
        "                'total_area': result['total_area'],\n",
        "                'congestion': result['congestion'],\n",
        "                'safety_status': result['safety_status']\n",
        "            })\n",
        "\n",
        "        df = pd.DataFrame(df_data)\n",
        "        df.to_csv(csv_path, index=False, encoding='utf-8-sig')\n",
        "        print(f\"\\nâœ… ë¶„ì„ ê²°ê³¼ë¥¼ CSVë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤: {csv_path}\")\n",
        "\n",
        "    return analysis_results\n",
        "\n"
      ],
      "metadata": {
        "id": "HSzoHibtg5Id"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ============================================================================\n",
        "# [ë°•ë¬´ë¦¼ íŒŒì¼] Section 5: í†µí•© ì‹¤í–‰ í•¨ìˆ˜\n",
        "# ============================================================================"
      ],
      "metadata": {
        "id": "brUeI5G2hCq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_integrated_system(model, test_loader, device, class_map, base_path=None):\n",
        "    \"\"\"\n",
        "    ========================================================================\n",
        "    íŒ€ì¥ ì½”ë“œ + ë°•ë¬´ë¦¼ ë¶„ì„ì˜ ì™„ì „ í†µí•© ì‹¤í–‰\n",
        "    ========================================================================\n",
        "\n",
        "    ì´ í•¨ìˆ˜ëŠ” ë‹¤ìŒ ìˆœì„œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤:\n",
        "    1. ResultPathManager ì´ˆê¸°í™”\n",
        "    2. save_predictions_to_coco() ì‹¤í–‰ â†’ Result.json ìƒì„±\n",
        "    3. process_team_result_json() ì‹¤í–‰ â†’ ë¶„ì„\n",
        "\n",
        "    ì…ë ¥:\n",
        "        model: íŒ€ì¥ì˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸\n",
        "        test_loader: í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë”\n",
        "        device: 'cuda' ë˜ëŠ” 'cpu'\n",
        "        class_map: í´ë˜ìŠ¤ ë§¤í•‘\n",
        "        base_path: ì €ì¥ ê²½ë¡œ (Noneì´ë©´ ìë™ ì„¤ì •)\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"\\n\" + \"â–ˆ\"*70)\n",
        "    print(\"  ğŸš€ íŒ€ì¥ ì½”ë“œ + ë°•ë¬´ë¦¼ ë¶„ì„ í†µí•© ì‹œìŠ¤í…œ ì‹œì‘\")\n",
        "    print(\"â–ˆ\"*70)\n",
        "\n",
        "    # 1. ê²½ë¡œ ê´€ë¦¬ì ì´ˆê¸°í™”\n",
        "    pm = ResultPathManager(base_path)\n",
        "\n",
        "    # 2. íŒ€ì¥ ì½”ë“œ ì‹¤í–‰: Result.json ìƒì„±\n",
        "    print(\"\\n[Step 1/2] íŒ€ì¥ ì½”ë“œ ì‹¤í–‰\")\n",
        "    print(\"-\" * 70)\n",
        "    result_json = save_predictions_to_coco(\n",
        "        model=model,\n",
        "        test_loader=test_loader,\n",
        "        device=device,\n",
        "        class_map=class_map,\n",
        "        path_manager=pm\n",
        "    )\n",
        "\n",
        "    # 3. ë°•ë¬´ë¦¼ ë¶„ì„ ì‹¤í–‰\n",
        "    print(\"\\n[Step 2/2] ë°•ë¬´ë¦¼ ë¶„ì„ ì‹¤í–‰\")\n",
        "    print(\"-\" * 70)\n",
        "    analysis_results = process_team_result_json(\n",
        "        result_json=result_json,\n",
        "        path_manager=pm\n",
        "    )\n",
        "\n",
        "    print(\"\\n\" + \"â–ˆ\"*70)\n",
        "    print(\"  âœ… í†µí•© ì‹œìŠ¤í…œ ì™„ë£Œ\")\n",
        "    print(\"â–ˆ\"*70)\n",
        "\n",
        "    return result_json, analysis_results\n",
        "\n"
      ],
      "metadata": {
        "id": "XdkZ9xHThIMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ============================================================================\n",
        "# ì£¼ìš” ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ë° ì‚¬ìš© ì˜ˆì‹œ\n",
        "# ============================================================================"
      ],
      "metadata": {
        "id": "dbGtIyLVhM5K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"âœ… í†µí•© íŒŒì¼ ë¡œë“œ ì„±ê³µ!\")\n",
        "    print(\"=\"*70)\n",
        "    print(\"\\në‹¤ìŒ í•¨ìˆ˜ë“¤ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\")\n",
        "    print(\"  1. run_integrated_system() - ì „ì²´ í†µí•© ì‹¤í–‰\")\n",
        "    print(\"  2. save_predictions_to_coco() - ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥\")\n",
        "    print(\"  3. process_team_result_json() - ê²°ê³¼ ë¶„ì„\")\n",
        "    print(\"  4. MurimFinalIntegration - ì§€ëŠ¥í˜• ë¶„ì„ ì—”ì§„\")\n",
        "    print(\"  5. PathManager - ë°•í•­ì•„ ê²½ë¡œ ê´€ë¦¬\")\n",
        "    print(\"  6. ResultPathManager - ë°•ë¬´ë¦¼ ê²°ê³¼ ê²½ë¡œ ê´€ë¦¬\")\n",
        "    print(\"\\nì‚¬ìš© ì˜ˆì‹œ:\")\n",
        "    print(\"  result_json, analysis = run_integrated_system(\")\n",
        "    print(\"      model=your_model,\")\n",
        "    print(\"      test_loader=test_loader,\")\n",
        "    print(\"      device=device,\")\n",
        "    print(\"      class_map=class_map\")\n",
        "    print(\"  )\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeX7PMf3hOni",
        "outputId": "959d4236-880a-4a46-cc71-27a46c625afa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "âœ… í†µí•© íŒŒì¼ ë¡œë“œ ì„±ê³µ!\n",
            "======================================================================\n",
            "\n",
            "ë‹¤ìŒ í•¨ìˆ˜ë“¤ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n",
            "  1. run_integrated_system() - ì „ì²´ í†µí•© ì‹¤í–‰\n",
            "  2. save_predictions_to_coco() - ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥\n",
            "  3. process_team_result_json() - ê²°ê³¼ ë¶„ì„\n",
            "  4. MurimFinalIntegration - ì§€ëŠ¥í˜• ë¶„ì„ ì—”ì§„\n",
            "  5. PathManager - ë°•í•­ì•„ ê²½ë¡œ ê´€ë¦¬\n",
            "  6. ResultPathManager - ë°•ë¬´ë¦¼ ê²°ê³¼ ê²½ë¡œ ê´€ë¦¬\n",
            "\n",
            "ì‚¬ìš© ì˜ˆì‹œ:\n",
            "  result_json, analysis = run_integrated_system(\n",
            "      model=your_model,\n",
            "      test_loader=test_loader,\n",
            "      device=device,\n",
            "      class_map=class_map\n",
            "  )\n"
          ]
        }
      ]
    }
  ]
}